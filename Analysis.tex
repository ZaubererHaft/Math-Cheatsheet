\section{Relle Zahlen}

\begin{definition}
	Eine Menge $A$ heißt \emph{abzählbar}, falls es eine surjektive Abbildung $\f{\naturalset}{A}$ gibt.
\end{definition}

\begin{definition}
	Die reellen Zahlen sind angeordnet, d.h. es gibt ein Prädikat $a > 0$ sodass
	\begin{enumerate}[noitemsep]
		\item $\forallinreal{a}$ gilt genau einer der Aussagen $a = 0, a < 0, -a < 0$
		\item $\forallinreal{a,b}$ mit $a > 0, b > 0$ gilt: $a + b > 0, a \cdot b > 0$
	\end{enumerate}
\end{definition}

\begin{definition}
	Folgende Mengen nennen wir Intervalle:
	\begin{align}
		(a,b) &:= \{ \inreal{x} \medspace | \medspace  a    < x    < b \} & \textnormal{offenes Intervall}       \\
		[a,b] &:= \{ \inreal{x} \medspace | \medspace  a \leq x \leq b \} & \textnormal{geschlossenes Intervall} \\
		(a,b] &:= \{ \inreal{x} \medspace | \medspace  a    < x \leq b \} & \textnormal{halboffenes Intervall}   \\
		[a,b) &:= \{ \inreal{x} \medspace | \medspace  a \leq x    < b \} & \textnormal{halboffenes Intervall}	
	\end{align}
\end{definition}

\begin{definition}
	Eine Menge $M \subseteq \realset$ heißt \emph{beschränkt}, wenn
	\begin{enumerate}[noitemsep]
		\item $\exists s_0 \in \realset : \forallin{a}{M} : a \leq s_0$; $s_0$ heißt \emph{Obere Schranke}
		\item Ist $s_0$ zusätzlich die kleinste obere Schranke, so heißt $s_0$ \emph{Supremum}
		\item $\exists s_0 \in \realset : \forallin{a}{M} : s_0 \leq a$; $s_0$ heißt \emph{Untere Schranke}
		\item Ist $s_0$ zusätzlich die größte untere Schranke, so heißt $s_0$ \emph{Infimum}
	\end{enumerate}
\end{definition}

\begin{satz}[Supremumsaxiom]
	Es gilt:
	\begin{enumerate}[noitemsep]
		\item Jede nichtleere nach oben beschränlte Menge $M \subseteq \realset$ besitzt ein Supremum, $sup(M) \in \realset$
		\item Jede nichtleere nach unten beschränlte Menge $M \subseteq \realset$ besitzt ein Infimum, $inf(M) \in \realset$
		\item $sup(M) \in M \rightarrow sup(M)$ heißt auch Maximum von $M$
		\item $inf(M) \in M \rightarrow inf(M)$ heißt auch Minimum von $M$
	\end{enumerate}
\end{satz}

\begin{satz}[Archimedizität]
	$\realset$ ist archimedisch, d.h. $\forallinreal{a} : \exists n \in \naturalset : a < n $. Jede relle Zahl besitzt also ein natürliches Supremum. Insbesondere gilt auch (offensichtlich, aber für Konvergenzbeweise hilfreich): $\frac{1}{n} < a$.
\end{satz}

\begin{satz}[Abschätzungen]
	Es gelten die folgenden Abschätzungen:
	
	\begin{enumerate}[noitemsep]
		\item \textbf{\emph{Dreiecksungleichung:}} $\forallinreal{x,y} : | x + y | \leq |x| + |y|$
		\item \textbf{\emph{Umgekehrte Dreiecksungleichung:}} 	$\forallinreal{x,y} : | x + y | \geq ||x| - |y||$
		\item \textbf{\emph{Cauchy-Schwarz-Ungleichung:}} 	$\forallinreal{x,y}^n : | <x + y> | \leq ||x|| + ||y||$
		\item \textbf{\emph{Abschätzen von Polynomen}} 	$ax^2 + bx + c \leq (a + b + c)x^2 $
		\item \textbf{\emph{Abschätzen der Wurzel:}} 	$\sqrt{ab} \leq \frac{a + b}{2}$
		\item \textbf{\emph{Bernoulli-Ungleichung:}} 	$(1+x)^n \geq 1 + nx$ für $x > -1$	
	\end{enumerate}
	
\end{satz}

\begin{satz}[Binomischer Lehrsatz]
	$\sum_{k=0}^{n} \binom{n}{k}a^k b^{n-k} = (a+b)^n$ 
\end{satz}

\section{Folgen}

\begin{definition}
	Eine Folge reeller Zahlen ist eine Abbildung $\naturalset \rightarrow \realset : n \rightarrow a_n$. $\sequencean$ beschreibt dabei die Folge, $a_n$ einen Folgenindex
\end{definition}


\begin{definition}
	Eine Folge $\sequencean$ konvergiert gegen $a \in \realset$ genau dann wenn \\ $\forall \epsilon > 0 : \exists n_0 \in \naturalset : \forall n \geq n_0 : | a_n - a | < \epsilon$, d.h. egal wie klein $\epsilon$, findet man eine Indexschranke $n_0$ sodass alle Folgeindices $a_n$ einen Abstand zu $a$ kleiner als $\epsilon$ haben. Wir schreiben $\liminfty{n} a_n = a$
\end{definition}

\begin{definition}
	Eine Folge $\sequencean$ divergiert, wenn sie nicht konvergiert. Sie konvergiert zusätzlich uneigentlich gegen
	\begin{enumerate}[noitemsep]
		\item $+ \infty$ genau dann wenn $\forall k > 0 : \exists n_0 \in \naturalset : \forall n \geq n_0 : a_n \geq k$, d.h. ab einen Index sind all $a_n \geq k$
		\item $- \infty$ genau dann wenn $\forall k > 0 : \exists n_0 \in \naturalset : \forall n \geq n_0 : a_n \leq -k$, d.h. ab einen Index sind all $a_n \leq -k$		
	\end{enumerate}
\end{definition}

\begin{definition}
	Eine Folge $\sequencean$ heißt \emph{beschränkt}, falls $\exists c > 0 : \forallin{n}{\naturalset} : a_n \leq c$
\end{definition}

\begin{satz}[Rechenregeln für Grenzwerte]
	Falls $\liminfty{n} a_n = a \in \realset$ sowie \\ $\liminfty{n} b_n = b \in \realset$, gilt:
	\begin{enumerate}[noitemsep]
		\item $\liminfty{n} (a_n \pm b_n) = \liminfty{n} a_n \pm \liminfty{n} b_n = a \pm b $
		\item $\liminfty{n} c \cdot a_n = c \cdot \liminfty{n} a_n = c \cdot a  $
		\item $\liminfty{n} a_nb_n = \liminfty{n} a_n \cdot \liminfty{n} b_n = ab  $
		\item $b \neq 0 \rightarrow\liminfty{n} \frac{a_n}{b_n} = \frac{\liminfty{n} a_n}{\liminfty{n} b_n} = \frac{a}{b} $
		\item $\liminfty{n} \sqrt{a_n} = \sqrt{a} $
		\item $\liminfty{n} |a_n| = |a| $
	\end{enumerate}
\end{satz}

\begin{satz}[Einschließungsregel]
	Es gelte $a_n \leq b_n \leq c_n$ für alle bis auf endlich viele $n$. Falls $\liminfty{n} a_n = \alpha$ und $\liminfty{n} c_n = \alpha $, dann ist auch $\liminfty{n} b_n = \alpha$.
\end{satz}

\begin{definition}[Monotone Folgen]
	Eine Folge $\sequencean$ heißt
	\begin{enumerate}[noitemsep]
		\item \emph{monoton fallend}, falls $a_n \geq a_{n+1}$ für alle $a_n$
		\item \emph{monoton steigend}, falls $a_n \leq a_{n+1}$ für alle $a_n$
		\item Gilt sogar $<$ bzw. $>$, so spricht man von \emph{strenger Monotonie}
	\end{enumerate}
\end{definition}

\begin{satz}[Monotonie und Konvergenz]
	Es gilt:
	\begin{enumerate}[noitemsep]
		\item $\sequencean$ monoton wachsend $\rightarrow \liminfty{n} a_n = sup(a_n)$
		\item $\sequencean$ monoton fallend $\rightarrow \liminfty{n} a_n = inf(a_n)$
		\item Jede beschränkte monotone Folge konvergiert
		\item Jede unbeschränkte monotone Folge konvergiert uneigentlich gegen $\pm \infty$
	\end{enumerate}
\end{satz}

\begin{definition}[Asymptotische Gleichheit]
	 $\sequencean$,  $\sequencebn$ heißen asymptotisch gleich, falls $\liminfty{n} \frac{a_n}{b_n} = 1$. Man schreibt: $a_n \backsimeq b_n$
\end{definition}

\section{Reihen}


\begin{definition}
	Zu einer Folge $\sequencean$ sei $(s_n)_{n \in \naturalset}$ mit $s_n := \sum_{k=0}^{n} a_k$ die Folge der Partialsummen. $\liminfty{n} s_n = \liminfty{n} \sum_{k=0}^{n} a_k = \serieskzeroinfty{a}$ heißt Werte der Reihe. Die Reihe konvergiert, wenn $(s_n)_{n \in \naturalset}$ konvergiert, sonst divergiert sie.
\end{definition}

\begin{satz}[Konvergenzkriterium]
	 $\serieskzeroinfty{a} $ konvergiert $\rightarrow \liminfty{k} a_k = 0$
\end{satz}

\begin{satz}[Majorantenkriterium]
	Es gilt:
	\begin{enumerate}[noitemsep]
		\item Findet man zur Reihe	$\serieskzeroinfty{a}$ eine Reihe $\serieskzeroinfty{b} $ sodass $b_k \geq |a_k|$, dann gilt: $\serieskzeroinfty{b}$ konvergiert $\rightarrow \sum_{k=0}^{\infty} a_k $ konvergiert. $\serieskzeroinfty{b} $ heißt Majorante
		\item Findet man zur Reihe	$\serieskzeroinfty{a}$ eine Reihe $\serieskzeroinfty{b} $ sodass $|b_k| \leq a_k$, dann gilt: $\serieskzeroinfty{b}$ divergiert $\rightarrow \sum_{k=0}^{\infty} a_k $ divergiert. $\serieskzeroinfty{b} $ heißt Minorante	
	\end{enumerate}
\end{satz}

\begin{satz}[Konvergenzkriterium]
	Sind die Folgen $\sequencean$ und $\sequencebn$ asymptotisch gleich, dann sind $\serieskzeroinfty{a}$ und $\serieskzeroinfty{b}$ entweder beide konvergent oder beide divergent.
\end{satz}

\begin{satz}[Quotientenkriterium]
	Sei $a_k \neq 0$ bis auf endlich viele $k$. Dann gilt:
	\begin{equation}
		\liminfty{k} | \frac{a_{k + 1}}{a_k} | = 
		\begin{cases}
		< 1 & \rightarrow \sum_{k=0}^{\infty} a_k \medspace \textnormal{ist konvergent} \\ 
		> 1 & \rightarrow \sum_{k=0}^{\infty} a_k \medspace \textnormal{ist divergent}  \\
		= 1 & \rightarrow \textnormal{keine Aussage möglich}
		\end{cases}
	\end{equation}
\end{satz}

\begin{satz}[Leibnizkriterium]
	Sei $(a_k)_{k \in \naturalset}$ monoton fallend und $\liminfty{k} a_k = 0$. Dann ist $\sum_{k=0}^{\infty} (-1)^k a_k$ konvergent.
\end{satz}

\begin{definition}
	$\serieskzeroinfty{a}$ ist absolut konvergent, wenn 	$\sum_{k=0}^{\infty} | a_k | $ konvergiert.
\end{definition}

\begin{satz}[Integralkriterium]
	Sei $\f{[1,\infty]}{[0, \infty]}$ monoton fallend. 	$\sum_{k=1}^{\infty} f(k) $ konvergiert $\leftrightarrow \int_{1}^{\infty} f(x) \medspace dx $ konvergiert
\end{satz}

\begin{satz}[Rechenregeln für konvergente Reihen]
	Sind $\serieskinfty{1}{a}$ und $\serieskinfty{1}{b}$ konvergente Reihen, dann gilt:
	\begin{enumerate}[noitemsep]
		\item \emph{\textbf{Summe konvergenter Reihen:}} $\serieskzeroinfty{a} + \serieskzeroinfty{b} = \sum_{k=0}^{\infty} (a_k + b_k)$
		\item \emph{\textbf{Multiplikation mit einer Konstante:}} $c \cdot \sum_{k=0}^{\infty} a_k = \sum_{k=0}^{\infty} c \cdot a_k$
		\item \emph{\textbf{Cauchy-Produkt:}} Sind beide Reihen absolut konvergent, dann auch $\sum_{k=0}^{\infty} c_k$, wobei $c_k = \sum_{l=0}^{\infty} a_lb_{k-l}$
		\item \emph{\textbf{Divergente Teilsumme:}}  Ist $\serieskzeroinfty{b}$ divergent, dann auch $\sum_{k=0}^{\infty} (a_k + b_k) $
	\end{enumerate}
\end{satz}

\begin{satz}[Bekannte Reihen]
	Folgende Reihen sind zu merken:
	\begin{enumerate}[noitemsep]
	\item \emph{\textbf{Harmonische Reihe:}} $\sum_{k=1}^{\infty} \frac{1}{k} = \infty$ (Divergenz)
	\item \emph{\textbf{Geometrische Reihe:}} $\sum_{k=0}^{\infty} z^k = \frac{1}{1 - z}$, falls $|z| < 1$
	\item \emph{\textbf{Teleskopreihe Reihe:}}  $\sum_{k=1}^{\infty} \frac{1}{k(k+1)} = 1$
	\item \emph{\textbf{Riemannsche Zetafunktion:}} $\zeta(s) = \sum_{k=1}^{\infty} \frac{1}{k^s}$ ist konvergent für $s>1$	
	\item \emph{\textbf{Exponentialreihe:}} $e^x = \sum_{k=0}^{\infty} \frac{x^k}{k!}$ konvergiert	
\end{enumerate}
\end{satz}

\section{Stetigkeit}
\begin{definition}
	Für eine Funktion $\frr$ definiert man $\liminfty{x} f(x) = b \in \realset \cup \{\pm \infty\}$, wenn für jede relle Folge $(x_n)_{n \in \naturalset}$ mit $\liminfty{n} = + \infty$ gilt, dass $\liminfty{n} f(x_n) = b$ ist. Analog gilt dies für $- \infty$
\end{definition}

\begin{definition}[Stetigkeit]
	Eine Funktion $\f{D}{\realset}$ heißt im Punkt $x \in D$ stetig, falls für alle Folgen $(x_n)_{n \in \naturalset}$ in $D$ mit $\liminfty{n} x_n = x$ gilt: $\liminfty{n} f(x_n) = f(x)$. Man schreibt dann auch $\limto{x}{y} f(y) = f(x)$. $f$ ist stetig auf $D$, wenn $f$ in jedem $x \in D$ stetig ist. 
\end{definition}

\begin{definition}[Rechts-/Linksseitiger Grenzwert]
	Man schreibt $\limdown{x}{x_0} f(x) = c$, wenn für jede Folge $(x_n)_{n \in \naturalset}$ mit $x_n > x_0$ für alle $n$ und $\limto{n}{x_n} = x_0$ gilt, dass $\liminfty{n} f(x_n) = c$. Man spricht vom \emph{Rechtsseitigem Grenzwert}. Analog definiert man den \emph{linksseitigen Grenzwert}.
\end{definition}

\begin{satz}[Rechenregeln stetiger Funktionen]
	Summen und Produkte stetiger Funktionen sind stetig. Die Komposition stetiger Funktionen ist stetig. Polynome und rationale Funktionen sind stetig. Die Betragsfunktion, Wurzelfunktion und die Exponentialfunktion sind stetig.
\end{satz}

\begin{satz}[Zwischenwertsatz]
	Sei $\fab$ stetig. Sei $y \in \realset$ und $f(a) < y < f(b)$ oder $f(b) < y < f(a)$. Dann gilt: $\exists x \in (a,b) : f(x) = y$
\end{satz}

\begin{satz}
	Sei $(n_k)_{k \in \naturalset}$ eine streng monoton wachsende Folge in $\naturalset$. Dann heißt  $(a_{n_k})_{k \in \naturalset}$ \emph{Teilfolge} von $\sequencean$. $a^*$ heißt \emph{Häufungspunkt} der Folge  $\sequencean$, falls es eine Teilfolge  $(a_{n_k})_{k \in \naturalset}$ mit $\liminfty{k} a_{n_k} = a^*$ gibt.
\end{satz}

\begin{satz}[Bolzano-Weierstrass]
	Jede beschränkte Folge in $\realset$ besitzt mindestens eine konvergente Teilfolge und damit einen Häufungspunkt.
\end{satz}

\begin{definition}
	Eine Menge $A \subseteq \realset$ heißt abgeschlossen, wenn für jede Folge $(x_n)_{n \in \naturalset}$ in $A$ gilt: $\liminfty{n} x_n = x \rightarrow x\in A$. Eine Menge $K \subseteq \realset$ heißt kompakt, wenn $K$ abgeschlossen und beschränkt ist. Jede kompakte Menge besitzt ein Minimum und ein Maximum.
\end{definition}

\begin{satz}
	Sei $K \subseteq \realset$ kompakt. Jede stetige Funktion $\f{K}{\realset}$ nimmt auf $K$ ihr Maximum und Minimum an, d.h. $\exists \bar{x}, \underline{x}: \forallin{x}{K} : f(\underline{x}) \leq f(x) \leq f(\bar{x})$. Man schreibt:
	
	\begin{enumerate}[noitemsep]
		\item $\underline{x} = argmin \{ f(x) \} \medspace$, $f(\underline{x}) = min \{f(x)\}$
		\item $\bar{x} = argmax \{ f(x) \} \medspace$, $f(\bar{x}) = max \{f(x)\}$
	\end{enumerate}

	Achtung: $\bar{x}, \underline{x}$ müssen nicht eindeutig sein.
\end{satz}

\begin{definition}[Lipschitz-Stetigkeit]
	Anschaulich heißt Lipschitz-Stetigkeit, dass eine Funktion $\f{\realset}{\realset}$ nicht zu schnell steigt:
	\begin{align*}
		\forallin{x_1, x_2}{\realset} : |f(x_1) - f(x_2)| \leq L \cdot |x_1 - x_2|
	\end{align*}
\end{definition}
	
\section{Funktionen}

\begin{tikzpicture}
	\begin{axis}[
	width=200,
	height = 150,
	ymin=-2,
	ymax=4,
	xmin=2,
	xmax=1,
	samples=100,
	grid=both,
	no markers,
	axis equal,
	axis x line=center,
	axis y line=center,
	]

		\addplot  {e^x};
		\addlegendentry{$e^x$}
		\addplot {ln (x)};	
		\addlegendentry{$ln (x)$}
	\end{axis}
\end{tikzpicture}

\begin{definition}[Exponentialfunktion]
	$e^x := \liminfty{n} (1 + \frac{x}{n})^n = \sum_{k=0}^{\infty} \frac{x^k}{k!}$
	\begin{description} [noitemsep]
		\item Grenzwerte: $\liminfty{x} e^x = \infty$, $\limninfty{x} e^x = 0$, $\limto{x}{0} e^x = 1$
		\item Ableitung: $\frac{\partial}{\partial x}(e^x) = e^x$, $\frac{\partial}{\partial x}(e^{-x}) = -e^{-x}$		
		\item Abschätzung: $ 0 \leq 1 + x \leq e^x$,  $x < 1 \rightarrow e^x \leq \frac{1}{1 - x}$ 
		\item Rechenregeln: $e^x \cdot e^y = e^{x+y}$, $e^x \div e^y = e^{x-y}$
		\item Weitere Eigenschaften: stetig auf $\realset$, differenzierbar auf $\realset$, streng monoton wachsend, Wertemenge: $(0, \infty)$, $\liminfty{x} \frac{e^x}{x^m} = \infty$, $\limdown{x}{0} \frac{e^x - 1}{x} = 1$
		\item Komplexe Exponentialfunktion: $e^{x+iy} = e^x(cos(y) + i sin(y)) \rightarrow e^{iy} = cos(y) + i sin(y)$
	\end{description}
\end{definition}

\begin{definition}[Logarithmusfunktion]
	$ln(e^x) := x$, $ln : (0, \infty) \rightarrow \realset$
	
	\begin{description} [noitemsep]
		\item Grenzwerte: $\liminfty{x} ln (x) = \infty$, $\limdown{x}{0} ln (x )= - \infty$
		\item Ableitung: $\frac{\partial}{\partial x} (ln(x)) = \frac{1}{x}$, $\frac{\partial}{\partial x} (ln(x + a)) = \frac{1}{x + a}$
		\item Abschätzung: für $x > 1$ gilt $1 - \frac{1}{x} < ln(x) < x - 1$
		\item Rechenregeln: $ln(xy) = ln(x) + ln(y)$, $ln(x \div y) = ln(x) - ln(y)$, $ln(x^k) = k \cdot ln(x)$
		\item Weitere Eigenschaften: stetig auf $(0,\infty)$, differenzierbar auf $(0,\infty)$, streng monoton wachsend, Wertemenge: $(- \infty, \infty)$, $\limdown{x}{0} x \cdot ln(x) = 0$, $\lim_{x \mapsto \infty} \frac{x}{ln(x)^n} = \infty$,  $\liminfty{x} \frac{ln(x)}{ln(ln(x))} = \infty$,  $\limdown{x}{0} \frac{ln(1+x)}{x} = 1$
	\end{description}
\end{definition}

\begin{definition}[Allgemeine Logarithmus - und Potenzfunktion]
 $\medspace$	\\ $x > 0, a \in \realset$ : $x^a = e^{ln(x^a)} = e^{a ln(x)}$ \\ $b^x = y \leftrightarrow x = log_b \leftrightarrow y = \frac{ln (y)}{ln(b)}$
	\begin{description} [noitemsep]
		\item Grenzwerte: $\liminfty{x} x^a = \begin{cases}
		+ \infty & a > 0 \\ 
		1        & a = 0  \\
		0        & a < 0
		\end{cases} \medspace \medspace $,
		$\limdown{x}{0} x^a = \begin{cases}
		0        & a > 0 \\ 
		1        & a = 0  \\
		+ \infty & a < 0
		\end{cases}$,\\
		 $\liminfty{x} \frac{x^a}{b^x} = 0$, $a > 0 \rightarrow \limdown{x}{0} x^a ln(x) = 0$, $\limdown{x}{0} \frac{ln(1+x)}{x} = 1$
		\item Ableitung: $\frac{\partial}{\partial x} (x^a) = a x^{a - 1}$, $\frac{\partial}{\partial x}(b^x) = ln(x) \cdot b^x$
		\item Rechenregeln: $x^{\frac{m}{n}} = \sqrt[m]{x^n} = (\sqrt[m]{x})^n$
	\end{description}
\end{definition}

\section{Trigonometrische Funktionen}

\begin{definition}[Einheitskreis]
Sinus und Kosinus beschreiben die Länge der Ankathete bzw. Gegenkathete im Einheitskreis.

\begin{multicols}{2}
	\begin{tikzpicture}
	\begin{axis}[
		width=170,
		height = 170,
		ymin=-1.5,
		ymax=1.5,
		xmin=-1.5,
		xmax=1.5,
		samples=100,
		grid=both,
		no markers,
		axis x line=center,
		axis y line=center,
	]
		\addplot [thick, orange, domain=0:0.707]{x)};
		\addplot [thick, blue] coordinates {(0.707,0)(0.707,0.707)};
		\addplot [thick, domain=0:0.707, red]{0};
		\addplot [thick, gray, domain=0.707:1]{x)};
		\addplot [thick, magenta] coordinates {(1,0)(1,1)};		
		\addplot [domain=0:2*pi,samples=50]({cos(deg(x))},{sin(deg(x))});
	\end{axis}
	\end{tikzpicture}
	\begin{itemize}[label={}, noitemsep]
		\item \textcolor{red}{Ankathete} $= cos(\phi) = a$
		\item \textcolor{blue}{Gegenkathete} $= sin(\phi) = b$
		\item \textcolor{orange}{Hypthenuse} $= 1 \overset{\text{Pythagoras}}{=} cos(\phi)^2 + sin(\phi)^2 = c$	
		\item \textcolor{magenta}{Tangente(x)} $= tan(\phi)$			
		\item $\pi := \frac{\textnormal{Kreisumfang U}}{\textnormal{Durchmesser d}} \overset{\text{Einheitskreis}}{=} \frac{U}{2} \leftrightarrow 2 \pi = U $
		\item $\rightarrow$ Kosinus und Sinus sind $2 \pi$ periodisch
		\item $\rightarrow cos(2 \pi x) = cos(x)$, $sin(2 \pi x) = sn(x)$
	\end{itemize}
\end{multicols}
\end{definition}

\begin{definition}[Rechtwinkliges Dreieck]
	Der (Ko)sinus eines Winkels beschreibt das Verhältnis der Länge der \textcolor{red}{Ankathete}/ \textcolor{blue}{Gegenkathete} zur \textcolor{orange}{Hypothenuse} eines rechtwinkligen Dreiecks
\end{definition}

\begin{multicols}{2}
\begin{tikzpicture}[scale=0.8]
\coordinate (a) at (4.4,0) {};
\coordinate (b) at (0,0) {};
\coordinate (c) at (2,2) {};
\draw[thick,red] (b) -- (c) node [midway, above, sloped] (TextNode) {a};
\draw[thick,blue] (c) -- (a) node [midway, above, sloped] (TextNode) {b};
\draw[thick,orange] (b) -- (a) node [midway, above, sloped] (TextNode) {c};
\draw pic["$\alpha$", draw=black, <->, angle eccentricity=1.2, angle radius=1cm]
{angle=a--b--c};
\draw pic["$90^{\circ}$", draw=black, <->, angle eccentricity=0.5, angle radius=1cm]
{angle=b--c--a};
\end{tikzpicture}
	\begin{itemize}[label={}, noitemsep]
	\item $cos (\alpha) = \frac{a}{c} = \frac{| \medspace \vec{a} \medspace|}{|\medspace \vec{c} \medspace |}$
	\item $sin (\alpha) = \frac{b}{c} = \frac{| \medspace \vec{b} \medspace|}{|\medspace \vec{c} \medspace |}$	
\end{itemize}
\end{multicols}

\begin{definition}[Skalarprodukt in geometrischer Definition]
	Das Skalarprodukt ordnet zwei Vektoren $a,b$ ein Skalar zu, das die Ähnlichkeit der Richtung beschreibt (, d.h. $0$ = identisch, $1$ = senkrecht).
	\begin{equation*}
	\langle a, b \rangle = |a| \cdot |b| \cdot cos(\alpha) = a^2 + b^2
	\end{equation*}
\end{definition}

\begin{definition}[Kreuzprodukt]
	Das Kreuzprodukt ordnet zwei Vektoren $a,b$ ein Vektor zu, der senkrecht auf beiden steht und als Länge den Flächeninhalt des durch $a,b$ aufgespannten Parallelogramms hat.
	
	\begin{multicols}{2}
			\begin{tikzpicture}[scale=0.75]
		\draw[-,fill=white!95!blue](0,0)--(3,0)--(4,1)--(1,1)--cycle;
		\node at (2,0.5) {$|\textcolor{red}{a}\times \textcolor{blue}{b}|$};
		\draw[ultra thick,-latex,red](0,0)--(3,0)node[midway,below]{$a$};
		\draw[ultra thick,-latex,blue](0,0)--(1,1)node[midway,above]{$b$};
		\draw[ultra thick,-latex,purple!50!purple](0,0)--(0,3)node[pos=0.7,right]{$a\times b$};
		\draw (0.6,0) arc [start angle=0,end angle=45,radius=0.6]
		node[pos=0.7,right]{$\alpha$};
		\end{tikzpicture}
		
		\begin{equation*}
			a \times b = det(e_3 , a , b) = \begin{pmatrix}
			 a_2b_3 - a_3b_2 \\
			 a_3b_1 - a_1b_3 \\
			 a_1b_2 - a_2b_1
			\end{pmatrix}
		\end{equation*}
	\end{multicols}
\end{definition}

\begin{definition}[Analytisch]
	Analytische Definition
	\begin{multicols}{2}
		\begin{tikzpicture}
		\begin{axis}[
		width=220,
		height = 160,
		ymin=-1.5,
		ymax=1.5,
		xmin=-6.3,
		xmax=6.3,
		samples=100,
		grid=both,
		no markers,
		axis x line=center,
		axis y line=center,
		    xtick={
			-6.28318, -4.7123889, -3.14159, -1.5708,
			1.5708, 3.14159, 4.7123889, 6.28318
		},
		    xticklabels={
			$-2\pi$, $-\frac{3\pi}{2}$, $-\pi$, $-\frac{\pi}{2}$,
			$\frac{\pi}{2}$, $\pi$, $\frac{3\pi}{2}$, $2\pi$
		}
		]
		\addplot  {sin (deg(x))};
		\addlegendentry{$sin (x)$}
		\addplot {cos (deg(x))};	
		\addlegendentry{$cos (x)$}
		\addplot [magenta, domain=-1.5:1.5]{tan (deg (x)};
		\addlegendentry{$tan (x)$}
		\end{axis}
		\end{tikzpicture}
		
		\begin{itemize}[label={}, noitemsep]
			\item $sin(x)  = \sum_{k = 0}^{\infty} (-1)^k \cdot \frac{x^{2k+1}}{(2k +1)!} \overset{\text{Euler}}{=} \frac{1}{2i}(e^{ix} - e^{-ix})$ 
			\item $cos(x)  = \sum_{k = 0}^{\infty} (-1)^k \cdot \frac{x^{2k}}{(2k)!}      \overset{\text{Euler}}{=} \frac{1}{2} (e^{ix} + e^{-ix})$
			\item $\rightarrow cos(x) = sin(x + \frac{\pi}{2})$, $sin(x) = cos(x - \frac{\pi}{2})$ 	
			\item $tan : (- \frac{\pi}{2}, \frac{\pi}{2}) \rightarrow (-\infty, \infty) : x \rightarrowtail \frac{sin(x)}{cos(x)}$
	\end{itemize}
	\end{multicols}
\end{definition}

\begin{definition}[Eigenschaften]
	Für Sinus, Kosinus und Tangens gilt:
	\begin{description}[noitemsep]
		\item $sin(0) = 0, sin( \frac{\pi}{2})=1, sin(\pi) = 0, sin(\frac{3 \pi}{2}) = -1, sin(2 \pi) = 0$
		\item $cos(0) = 1, cos (\frac{\pi}{2}) = 0, cos (\pi) = 1, cos(\frac{3 \pi}{2}) = 0, cos (2 \pi) = 1$
		\item $tan(0) = 0, tan(\pi) = 0, tan(2 \pi) = 0 \dots$
		\item Ableitung: $\frac{\partial}{\partial x}(cos(x)) = -sin(x), \frac{\partial}{\partial x}(sin(x)) = cos(x)$, \\ $\frac{\partial}{\partial x}(tan(x)) = \frac{1}{cos(x)^2} = 1 + tan(x)^2$
		\item Grenzwerte $\limto{x}{0} \frac{sin(x)}{x} = 1, \limto{x}{0} \frac{1 - cos(x)}{0.5x} = 1, \limdown{x}{0} \frac{tan (x)}{x} = 1$
		\item Rechenregeln: $cox(-x) = cos(x), sin(-x) = -sin(x)$ \\ $cos(x \pm y) = cos(x)cos(y) \pm sin(x)sin(y)$, \\ $sin(x \pm y) = sin(x)cos(y) \pm sin(y)cos(x)$
		\item Weitere Eigenschaften: stetig und differenzierbar auf dem gesamten Definitionsbereich
	\end{description}
\end{definition}


\begin{definition}[Umkehrfunktionen]
Für Sinus, Kosinus und Tangens seien die folgenden Umkehrfunktionen definiert:
	\begin{multicols}{2}
		\begin{tikzpicture}[scale=0.9]
			\begin{axis}[
			width=200,
			height = 200,
			domain=-3.1:3.1, 
			samples=500, 
			axis x line=center,
			axis y line=center,
			xtick={-3.14,-1.57,0,1.57,3.14}, 
			ytick={-1.57,1.57,3.14}, 
			xticklabels={$-\pi$, $-\frac{\pi}{2}$, $0$, $\frac{\pi}{2}$, $\pi$},
			yticklabels={$-\pi$/2,$\pi$/2,$\pi$},
			grid=both]
			\addplot[color = blue,domain=-1:1]  {asin(x)/180*pi};
			\addlegendentry{$arcsin (x)$}
			\addplot[color = red, domain=-1:1]  {acos(x)/180*pi};
			\addlegendentry{$arccos (x)$}
			\addplot[color = magenta]  {atan(x)/180*pi};
			\addlegendentry{$arctan (x)$}
			\end{axis}
		\end{tikzpicture}
			\begin{description}[noitemsep]
				\item $arcsin : [-1,1] \rightarrow [0, \pi] : x \mapsto sin^{-1}(x) $
				\item $arccos : [-1,1] \rightarrow [-\frac{\pi}{2},\frac{\pi}{2}] : x \mapsto cos^{-1}(x) $
				\item $arctan : \realset \rightarrow [-\frac{\pi}{2},\frac{\pi}{2}] : x \mapsto tan^{-1} $
			\end{description}
	\end{multicols}
\end{definition}

\begin{definition}[Hyperbolische Funktionen]
	content...
\end{definition}

\section{Komplexe Zahlen}

\begin{definition}
	Als Erweiterung der reellen Zahlen sei definiert:
	\begin{description}[noitemsep]
		\item $z \in \complexset, z = x + iy$, wobei $x,y \in \realset$ und $i := \sqrt{-1} \leftrightarrow i^2 = -1$
		\item $x := Re(z)$ nennt man \emph{Realteil} von $z$, $y := Im(z)$ heißt \emph{Imaginärteil} von $z$
		\item $\bar{z} = z^* := x - iy, |z| = \sqrt{x^2 + y^2}$
		\item $\rightarrow Re(z) = \frac{z + \bar{z}}{2}, Im(z) = \frac{z - \bar{z}}{2}$
	\end{description}
\end{definition}

\begin{definition}[Polardarstellung]
	Anstelle die Zahleneben $x,y$ einer komplexen Zahl zu verwenden, lässt sich alternativ die Länge $c$ der Zahl sowie der Winkel $\phi$ zur reellen Achse benutzen:
	
	\begin{tikzpicture}
	\begin{axis}[
	ticks=none,
	domain=0:2,
	width=220,
	height=150,
	xmax=1.5,
	ymax=1.25,
	axis x line=center,
	axis y line=center,
	xlabel style={at={(axis description cs:0.5,-0.0)},anchor=north},
	xlabel={$\realset$},
	ylabel style={at={(axis description cs:-0.0,.5)},rotate=90,anchor=south},
	ylabel={$\complexset$},
	no markers]
	
	\addplot [red, domain=0:1]{x}  node[above,pos=1] {$z = x + iy$};
	\addplot [blue, domain=0:1] coordinates {(1,0)(1,1)};	
	\node[right] at (40, 5)  {$a = c \cdot cos(\phi)$} ;
	\node[right] at (15, 50)  {$c = |z|$} ;
	\node[right] at (100, 50)  {$b = c \cdot sin(\phi)$} ;
	\node[right] at (15, 10)  {$\phi$} ;
	\end{axis}
	\end{tikzpicture}
	
	$(c, \phi) $ bezeichnet man als Polarkoordinaten der komplexen Zahl
	
\end{definition}

\begin{satz}[Euler'sche Formel]
	$e^{iy} = cos(x) + i sin(x)$
	
	\begin{description}[noitemsep]
		\item $\rightarrow e^{it}$ durchläuft den Einheitskreis 
		\item $\rightarrow e^{i \cdot 0} = e^{i \cdot 2k\pi} = 1, e^{-i\pi} = -1$
	\end{description}
	
\end{satz}

\pagebreak

\section{Frequenzanalyse und Fourier-Reihe}
\begin{definition}[Trigonometrisches Polynom]
	Man definiert analog zu regulären Polynomen Polynome mit trigonometrischen Funktionen mit Grad $n$ als Basis im Intervall $[-\frac{T}{2}, \frac{T}{2}]$ 
	\begin{align*}
		F_n(t) := \frac{a_0}{2} + \sum_{k=1}^{n} (a_k cos(k\omega t) + b_k sin(k \omega t))
	\end{align*}
	wobei $\omega := \frac{2 \pi}{T}$ und $a_k, b_k$ Fourierkoeffizienten genannt werden.
\end{definition}

\begin{satz}
	Unter Rücksichtnahme der Norm für Funktionen, $||f|| := \int_a^b |f(x)|^2$, minimieren für eine stetige, beschränkte Funktion $f$ die folgenden Koeffizienten das approximierende trigonometrische Polynom;
	
	\begin{align*}
		a_k = \frac{2}{T} \int_{-\frac{T}{2}}^{\frac{T}{2}} cos(k \omega t)f(t) dt,
		b_k = \frac{2}{T} \int_{-\frac{T}{2}}^{\frac{T}{2}} sin(k \omega t)f(t) dt,	
	\end{align*}
	
	An jeder Stelle, an der $f$ differenzierbar ist, konvergiert dann $F_n$ für $n \rightarrow \infty$ gegen den Funktionswert. Wir schreiben
	
	\begin{align*}
		f(t) = \frac{a_0}{2} + \sum_{k=1}^{\infty}a_k cos(k \omega t) + b_k sin(k \omega t)
	\end{align*}
\end{satz}

\begin{definition}[Spektrum]
	Für eine Funktion dargestellt als Fourierreihe, z.B. $f(t) = cos()$
\end{definition}

\pagebreak

\section{Differenzierbarkeit}

\begin{definition}[Landau-Symbole]
	Seien $f,g : \realset \rightarrow \complexset$ Funktionen, $x_0 \in \realset$
	\begin{description}[noitemsep]
		\item $f(x) = \mathcal{O}(g(x))$ für $x \rightarrow x_0$ falls: $\exists \epsilon > 0: \exists c > 0 : \forallxinreal$ mit $|x - x _0| < \epsilon : |f(x)| < c \cdot |g(x)|$, d.h. in einer Umgebung von $x_0$ wird $f(x)$ von $g(x)$ mal einer Konstante beschränkt.
		\item $f(x) = o(g(x))$ für $x \rightarrow x_0$ falls $\lim_{x \rightarrow x_0} \frac{f(x)}{g(x)} = 0 $
		\item $f(x) = \mathcal{O}(g(x))$ für $x \rightarrow \infty$ falls: $\exists M > 0: \exists c > 0 : \forall x > M : |f(x)| < c \cdot |g(x)|$, d.h. ab einer Schranke $M$ wird $f(x)$ durch $g(x)$ beschränkt.
		\item $f(x) = \mathcal{O}(g(x))$ für $x \rightarrow -\infty$ falls: $\exists M > 0: \exists c > 0 : \forall x < -M : |f(x)| < c \cdot |g(x)|$, d.h. ab einer Schranke $M$ wird $f(x)$ durch $g(x)$ beschränkt.	
		\item $f(x) = o(g(x))$ für $x \rightarrow x_0 \in \{\pm \infty\}$ falls $\lim_{x \rightarrow x_0} \frac{f(x)}{g(x)} = 0 $
	\end{description}
\end{definition}

\begin{definition}[Differenzierbarkeit]
	Eine Funktion $\f{I}{\realset}, I \subseteq \realset$ heißt differenzierbar in $x_0 \in I$, falls $\lim_{x \rightarrow x_0} \frac{f(x) - f(x_0)}{x - x_0}$ bzw. $\lim_{h \rightarrow 0} \frac{f(x_0 + h) - f(x_0)}{h}$ existiert. Man schreibt dafür $f'(x_0)$ (Lagrange), $\frac{\partial f}{\partial x_0}$ (Leibniz). Ist $f$ differenzierbar für alle $x_0 \in I$, so heißt $f$ differenzierbar.
\end{definition}

\begin{satz}[Rechenregeln differenzierbrer Funktionen]
	Seien $f,g : I \subseteq \realset \rightarrow \realset$ in $x \in I$ differenzierbar, $c \in \realset$.
	\begin{description}[noitemsep]
		\item $(c \cdot f)'(x) = c \cdot f'(x) $
		\item $(f + g)'(x) = f'(x) + g'(x) $
		\item $(f \cdot g)'(x) = f'(x) g(x) + f(x)g'(x) $  (Produktregel)
		\item $(\frac{f}{g})'(x) = \frac{f'(x) g(x) - f(x)g'(x)}{g(x)^2} $	 (Quotientenregel)
	\end{description}
\end{satz}

\begin{satz}[Kettenregel]
	Sei $\f{ D \subseteq \realset}{\realset}$, $g : E \subseteq \realset \rightarrow \realset$ und $g(E) \subseteq D$. Sei $x_0$ innererer Punkt von $E$, $g(x_0)$ innerer Punkt von $D$. Sei $g$ in $x_0$ und $f$ in $g(x_0)$ differenzierbar. Dann gilt: $(f \circ g)'(x_0) = f'(g(x_0)) \cdot g'(x_0)$
 \end{satz}

\begin{satz}[Ableitung der Umkehrfunktion]
	Sei $\f{I \subseteq \realset}{J \subseteq \realset} $ bijektiv und differenzierbar in $y_0$. Dann ist $f^{-1} : J \rightarrow I$ differenzierbar in $y_0$ und $(f^{-1})'=\frac{1}{f'(f^{-1}(y_0))}$
\end{satz}

\begin{satz}[Elementare Ableitungen]
	Es gelten folgende Ableitungen:
	\begin{multicols}{2}
		\begin{description}[noitemsep]
			\item $(c)' = 0$
			\item $(x^a)'=ax^{a-1}$
			\item $(e^x)'=e^x$
			\item $sin'(x) = cos(x)$
			\item $cos'(x) = -sin(x)$
			\item $tan'(x) = \frac{1}{cos(x)^2} = 1 + tan(x)^2$
			\item $ln'(x) = \frac{1}{x}$
			\item $arcsin'(x) = \frac{1}{\sqrt{1 -x^2}}$	
			\item $arccos'(x) = - \frac{1}{\sqrt{1 - x^2}}$	
			\item $arctan'(x) = \frac{1}{1 + x^2}$
			\item $(a^x)' = a^x ln(a)$
			\item $ln(u(x))'=\frac{u'(x)}{u(x)}$
		\end{description}
	\end{multicols}
\end{satz}

\section{Anwendungen der Ableitung}

\begin{satz}
	Sei $\fab$ differenzierbar auf $(a,b)$. Wenn $f$ in $x_0$ ein lokales Extremum besitzt, dann gilt $f'(x_0) = 0$.
\end{satz}

\begin{satz}[Mittelwertsatz]
	Sei $\fab$ differenzierbar auf $[a,b]$, differenzierbar auf $(a,b)$. Dann gibt es ein $\xi \in (a,b)$ sodass $\frac{f(b) - f(a)}{b - a} = f'(\xi)$.
\end{satz}

\begin{satz}[Satz von Rolle]
	Gilt neben dem Mittelwertsatz zusätzlich $f(a) = f(b)$, dann gibt es ein $\xi \in (a,b)$ sodass $f'(\xi) = 0$.
\end{satz}

\begin{satz}[Monotonie und Ableitungen]
	\begin{description}[noitemsep]
		\item $\forallin{x}{(a,b)}: f'(x) > 0 \rightarrow f$ ist auf $[a,b]$ streng monoton wachsend
		\item $\forallin{x}{(a,b)}: f'(x) < 0 \rightarrow f$ ist auf $[a,b]$ streng monoton fallend
		\item $\forallin{x}{(a,b)}: f'(x) \geq 0 \rightarrow f$ ist auf $[a,b]$ monoton wachsend
		\item $\forallin{x}{(a,b)}: f'(x) \leq 0 \rightarrow f$ ist auf $[a,b]$ monoton fallend
	\end{description}
\end{satz}

\begin{satz}
	Sei $\fabex$ differenzierbar, sei $f'(x_0) = 0, x_0 \in (a,b)$.
	\begin{description}[noitemsep]
		\item $f' \geq 0$ in $(a, x_0)$ und $f' \leq 0$ in $(x_0, b) \rightarrow x_0$ ist globales Maximum
		\item $f' \leq 0$ in $(a, x_0)$ und $f' \geq 0$ in $(x_0, b) \rightarrow x_0$ ist globales Minimum
	\end{description}
\end{satz}

\begin{satz}
	Seien $f,g : (a,b) \rightarrow \realset$ differenzierbar und $f' = g'$ auf $(a,b)$. Dann gibt unterscheiden sich $f,g$ nur um eine Konstante, d.h. $\exists c \in \realset : f = g + c$ auf $(a,b)$.
\end{satz}

\begin{satz}[L'Hospital]
	Seien $a,b \in \realset \cup \{+ \infty, - \infty\}$. Seien $f, g : (a,b) \rightarrow \realset$ differenzierbar mit $g'(x) \neq 0$. Sei $x_0 \in (a,b)$ und es gelte:
	\begin{enumerate}[noitemsep]
		\item $\lim_{x \rightarrow x_0} f(x) = 0 = \lim_{x \rightarrow x_0} g(x)$ oder
		\item$\lim_{x \rightarrow x_0} f(x) = \pm \infty = \lim_{x \rightarrow x_0} g(x)$
	\end{enumerate}
	Falls $\lim_{x \rightarrow x_0} \frac{f'(x)}{g'(x)}$ existiert, gilt: $\lim_{x \rightarrow x_0} \frac{f(x)}{g(x)} = \lim_{x \rightarrow x_0} \frac{f'(x)}{g'(x)}$.
\end{satz}

\begin{definition}
	Für zweimal differenzierbares $\fabex$ gilt:
	\begin{enumerate}[noitemsep]
		\item $f$ heißt \emph{konvex} $\leftrightarrow f'' \geq 0$ auf $(a,b)$
		\item $f$ heißt \emph{konkav} $\leftrightarrow f'' \leq 0$ auf $(a,b)$		
	\end{enumerate}
\end{definition}

\begin{satz}
	Sei $\fabex$ zweimal differenzierbar und $f'(x_0)=0$ und $\exists x_0 \in (a,b) : f'(x_0) = 0$.
	
	\begin{enumerate}[noitemsep]
		\item $f''(x_0) > 0 \rightarrow f$ besitzt in $x_0$ ein striktes lokales Minimum
		\item $f''(x_0) < 0 \rightarrow f$ besitzt in $x_0$ ein striktes lokales Maximum	
	\end{enumerate}
\end{satz}

\begin{satz}[Differenzierbarkeit und Stetigkeit]
	Ist $f$ differenzierbar, so ist $f$ stetig.
\end{satz}

\pagebreak

\section{Integrale}

\begin{multicols}{2}
	\begin{tikzpicture}[scale=0.75]
	\def\a{0.7}
	\def\b{4.2}
	\def\c{2.7}
	\def\L{0.5} % width of interval
	
	\pgfmathsetmacro{\Va}{2*sin(\a r+1)+4} \pgfmathresult
	\pgfmathsetmacro{\Vb}{2*sin(\b r+1)+4} \pgfmathresult
	\pgfmathsetmacro{\Vc}{2*sin(\c r+1)+4} \pgfmathresult
	
	\draw[->,thick] (-0.5,0) -- (6,0) coordinate (x axis) node[below] {$x$};
	\draw[->,thick] (0,-0.5) -- (0,7) coordinate (y axis) node[left] {$y$};
	\foreach \f in {0.7,1.2,1.7,2.2,...,4.7} {\pgfmathparse{2*sin(\f r+1)+4} \pgfmathresult
		\draw[fill=blue!20] (\f-\L/2,\pgfmathresult |- x axis) -- (\f-\L/2,\pgfmathresult) -- (\f+\L/2,\pgfmathresult) -- (\f+\L/2,\pgfmathresult |- x axis) -- cycle;}
	\node at (\a-\L/2+0.25,-5pt) {\footnotesize{$a=x_0$}};
	\node at (\b+\L/2+\L,-5pt) {\footnotesize{$b=x_n$}};
	\draw[blue] (\c-\L/2,0) -- (\c-\L/2,\Vc) -- (\c+\L/2,\Vc) -- (\c+\L/2,0);
	\draw[dashed] (\c,0) node[below] {\footnotesize{$\xi_j$}} -- (\c,\Vc) -- (0,\Vc) node[left] {$f(\xi_j)$};
	\node at (\a+5*\L/2 - 0.1,-5pt) {\footnotesize{$x_{j-1}$}};
	\node at (\a+7*\L/2,-5pt) {\footnotesize{$x_j$}};
	\node at (\a+5*\L,-5pt) {\footnotesize{$x_{j+1}$}};
	\draw[blue,thick,smooth,samples=100,domain=0.25:5.2] plot(\x,{2*sin(\x r+1)+4});
	\filldraw[black] (\c,\Vc) circle (.03cm);
	\end{tikzpicture}
	
	\begin{definition}[Riemann-Summe]
		Sei $Z$ eine Zerlegung von $[a,b]$ : $a = x_0 < x_1 < \dots < x_{n-1} < x_n = b$. Die Feinheit von $Z$ ist $|Z| = max_{1 \leq j \leq n}\{|x_j - x_{j-1}|\}$. Gegeben sei ein Zerlegung $Z$. Sei $\xi \in [x_{j-1}, x_j]$ mit $1 \leq j \leq n$ beliebig. $S_Z = \sum_{j=1}^{n} f(\xi) \cdot (x_j-x_{j-1})$ heißt \emph{Riemann-Summe}, wobei $f(\xi)$ Höhe der Rechtecksflächen.
	\end{definition}
\end{multicols}

\begin{definition}[Riemann-integrierbar]
	$\fab$ heißt \emph{Riemann-integrierbar}, falls für alle Zerlegungsfolgen $(Z_n)_{n \in \naturalset}$ mit Feinheit $|Z_n| \overset{n \rightarrow \infty}{\rightarrow} 0$ die zugehörigen Riemann-Summen $S_{Z_n}$ für jede Wahl der Zwischenpunkte gegen den selben Grenzwert $I(f)$ konvergieren: $\liminfty{n} \sum_{j=1}^n f(\xi_f) \cdot (x_j - x_{j-1}) = I(f) := \int_{a}^{b}f(x) dx$
\end{definition}

\begin{satz}[Rechenregeln für Integrale]
	Seien $f,g : [a,b] \rightarrow \realset$ Riemann-integrierbar, $\delta, \mu \in \realset$. Es gilt:
	\begin{description}[noitemsep]
		\item $\int_{a}^{a} f(x) dx = 0$, $\int_{b}^{a} f(x) dx = - \int_{a}^{b} f(x) dx$, $\int_{a}^{b} 1 dx = \int_{a}^{b} dx = b - a$
		\item $\int_{a}^{b} f(x) dx \geq 0$ für $f \geq 0$ auf $[a,b]$, $\int_{a}^{b} \delta f(x) + \mu g(x) dx = \delta \int_{a}^{b}f(x) dx + \mu \int_{a}^{b} g(x) dx$
		\item $\int_{a}^{b} f(x) dx = \int_{a}^{c} f(x) dx + \int_{c}^{b} f(x) dx$ für $a < b < c$
	\end{description} 
\end{satz}

\begin{satz}
	Jede stetige Funktion ist Riemann-integrierbar.
\end{satz}

\begin{satz}[Mittelwertsatz der Integralrechnung]
	Sei $\fab$ stetig, $\gab$ integrierbar und $g \geq 0$ oder $g \leq 0$. Dann gibt es ein $\xi \in [a,b]$ sodass $\int_{a}^{b}f(x)g(x) dx = f(\xi) \cdot \int_{a}^{b} g(x) dx$. Für $g=1$ ergibt sich der Spezialfall $\int_{a}^{b}f(x)dx = f(\xi) \cdot \int_{a}^{b} dx = f(\xi) \cdot (b - a)$
\end{satz}

\begin{satz}[Hauptsatz der Differential und Integralrechnung]
	Sei $\fab$ stetig. Die Funktion $\functionab{F}$ mit $F(x) = \int_{a}^{x} f(t) dt$ ist in jedem $x \in (a,b)$ differenzierbar und es gilt: $F'(x) = f(x)$.
\end{satz}

\begin{satz}
	Sei $\fab$ stetig und $\functionab{F}$ Stammfunktion von $f$. Dann gilt: $\int_{a}^{b}f(x)dx = F(b) - F(a) := [F(x)]_a^b$. Für eine Stammfunktion von $f$ schreibt man auch $\int f(x) dx$ (unbestimmtes Integral).
\end{satz}

\begin{satz}[Partielle Integration]
	Seien $\functionab{g,f}$ stetig differenzierbar. Dann gilt:
	\begin{description}[noitemsep]
		\item $\int_{a}^{b} f(x)g'(x)dx = [f(x)g(x)]_a^b - \int_{a}^{b} f'(x)g(x)dx$
		\item $\int f(x)g'(x)dx = f(x)g(x) - \int f'(x)g(x)dx$	
	\end{description}
\end{satz}

\begin{satz}[Integration durch Substitution]
	Seien $\functionab{g,f}$ stetig differenzierbar. Dann gilt für jede stetige Funktion $\function{f}{g([a,b])}{\realset}$:
	\begin{description}[noitemsep]
		\item $\int_{a}^{b} f(g(t))g'(t) = \int_{g(a)}^{g(b)}f(x)dx$
		\item $\int f(g(t))g'(t) = \int f(x)dx$
	\end{description}
\end{satz}


\section{Potenzreihen}

\begin{definition}
	Funktionsdarstellungen der Form $f(x) = \serieskzeroinfty{a}x^k, |x| < r$ nennt man Entwicklung von $f$ in eine Potenzreihe. Die größtmögliche Gültigkeitsschranke für Konvergenz nennt man Konvergenzradius der Potenzreihe.
\end{definition}

\begin{satz}[Taylor'sche Formel]
	Sei $\epsilon > 0, \f{(a-\epsilon, a +\epsilon)}{\realset}$ n-mal stetig differenzierbar. $f(x+h) = \sum_{k = 0}^n \frac{f^{(k)}(x)}{k!} \cdot h^k + o(h^n)$ für $h \rightarrow 0$. $T_{n}f(x; h) = \sum_{k = 0}^n \frac{f^{(k)}(x)}{k!} \cdot h^k$ heißt Taylorpolynom von $f$ in einer Umgebung um $x$. 
\end{satz}

\begin{satz}[Taylor'sche Formel mit Restglied] 
	Eine weitere Darstellung der Taylor'schen Formel an der Stelle $h$ ist:
	$T_{n}f(x; h) = \sum_{k = 0}^n \frac{f^{(k)}(h)}{k!} \cdot (x - h)^k + \frac{(x - h)^{(n + 1)}}{(n + 1)!} \cdot f^{n + 1}(\xi) $ 
\end{satz}

\begin{tikzpicture}
\begin{axis}[
    axis lines = left,
    legend pos=south east,
    width=10cm,height=8cm,
      axis x line=center,
    axis y line=center,
	xlabel = \(x\),
	ylabel = {\(f(x)\)}
]
\addplot[color=blue, samples=100, domain=-5:5]{cos(deg(x))};
\addlegendentry{\(cos(x)\)}
\addplot[domain=-5:5]{1};
\addlegendentry{\(p(x) = 1\)}
\addplot[color=orange,domain=-2:2]{1 - 0.5 * x^2};
\addlegendentry{\(p(x) = 1 - 0.5 x^2\)}
\addplot[color=green,domain=-2:2]{1 - 0.5 * x^2 + 1/24 * x^4};
\addlegendentry{\(p(x) = 1 - 0.5  x^2 + 1/24  x^4\)}
\end{axis}
\end{tikzpicture}

\begin{satz}[Taylor'sche Formel in 2D]
	content...
\end{satz}

\begin{satz}
	Zu jeder Potenzreihe $\serieskzeroinfty{a}x^k$ gibt es einen Konvergenzradius sodass $\forallin{z}{\complexset}$ gilt:
	\begin{description}[noitemsep]
		\item $|z| < r \rightarrow $ die Potenzreihe konvergiert absolut
		\item $|z| > r \rightarrow $ die Potenzreihe divergiert
		\item der Fall $|z| = r$ muss gesondert betrachtet werden
	\end{description}
	Falls die Folge $\sequence{\sqrt[k]{|a|}}{k}$ konvergiert, so ist $r = \frac{1}{\liminfty{k}\sqrt[k]{|a|_k}}$
\end{satz}

\begin{definition}
	Eine Funktion heißt \emph{analytisch}, wenn sie sich mit positivem Konvergenzradius in eine Potenzreihe entwickeln lässt.
\end{definition}

\begin{satz}
	Sind $f,g$ in $x=0$ analytisch, $f(x) = \serieskzeroinfty{a}x^k, |x| < r_f$, $g(x) = \serieskzeroinfty{b}x^k, |x| < r_g$. Dann gilt:
	\begin{enumerate}[noitemsep]
		\item $f'$ ist in $x=0$ analytisch und $f'(x) = \frac{\partial}{\partial x} \serieskzeroinfty{a}x^k = \sum_{k=0}^{\infty} \frac{\partial}{\partial x}a_kx^k, |x| < r_f$
		\item Die Koeffizienten sind eindeutig $a_k = \frac{f^{(k)}(0)}{k!}, k \in \naturalset_0$
		\item Stammfunktionen sind in $x=0$ analytisch: $\int_{0}^{x}f(t)dt = \int_{0}^{x}\serieskzeroinfty{a}t^k dt= \sum_{k=0}^{\infty}\int_{0}^{x}a_k t^k dt$
		\item $f + g, f \cdot g$ sind analytisch mit
		\begin{description}
			\item $(f + g)(x) = \sum_{k=0}^{\infty} (a_k+b_k)x^k, |x|=\min\{r_f, r_g\}$
			\item $(f \cdot g)(x) = \sum_{k=0}^{\infty} \sum_{j=0}^{k} a_jb_{k-j}x^k, |x|=\min\{r_f, r_g\}$
		\end{description}
	\end{enumerate}
\end{satz}

\pagebreak

\section{Mehr über Integrale}
\begin{definition}
	Ist $f : [a,b)$ auf $[\alpha, \beta]$ integrierbar für alle $a < \beta < b$, dann heißt $\int_{a}^{b} f(x) dx = \limto{\beta}{b} \int_{a}^{\beta} f(x) dx$ \emph{uneigentliches Integral}. Analog verfährt man mit der unteren Grenze.
\end{definition}

\begin{definition}
	Ist $f : (a,b)$ auf $[\alpha, \beta]$ integrierbar für alle $a < \alpha < \beta < b$, dann heißt $\int_{a}^{b} f(x) dx = \limto{\alpha}{a} \int_{\alpha}^{c} f(x) dx + \limto{\beta}{b} \int_{c}^{\beta} f(x) dx$ \emph{uneigentliches Integral}, falls die Grenzwerte für ein $c \in (a,b)$ existieren.
\end{definition}

\begin{definition}
	Wir betrachten $f(x,y)$. Für ein festes/konstantes $x$ schreiben wir die Ableitung $y \mapsto f(x,y) : \partial y f(x,y)$ oder $\partial_2 f(x,y)$.
\end{definition}

\begin{satz}
	Sei $f : [a,b] \times [c,d]$ stetig. Es gilt:
	\begin{enumerate}[noitemsep]
		\item $F : y \mapsto \int_{a}^{b} f(x,y) dx$ ist stetig
		\item (Fubini) $\int_{c}^{d} F(y) dx= \int_{c}^{d} \int_{a}^{b} f(x,y) dx dy =  \int_{a}^{b} \int_{c}^{d} f(x,y) dy dx $
		\item Besitzt $f$ eine stetig partielle Ableitung $\partial_y$, dann ist $F$ differenzierbar mit $F'(y) = \int_{a}^{b} \partial_y f(x,y) dx$ und $\frac{\partial}{\partial y} \int_{a}^{b} f(x,y) dx = \int_{a}^{b} \frac{\partial}{\partial y} f(x,y) dx$ 
	\end{enumerate}
\end{satz}

\begin{satz}
	Sei die Funktionsfolge $f_k : [a,b] \mapsto \realset$ integrierbar und es gebe $a_k \geq 0$ sodass $|f_k| \leq a_k$ für alle $x \in [a,b]$ und $\serieskinfty{1}{a} < \infty$. \\
	$\rightarrow f(x) = \sum_{k=1}^{\infty} f_k(x)$ konvergiert und es gilt: $\int_{a}^{b}f(x)dx = \int_{a}^{b} \sum_{k=1}^{\infty} f_k(x)dx =  \sum_{k=1}^{\infty} \int_{a}^{b}f_k(x) dx$
\end{satz}

\begin{satz}
	Seien $a,b \in \mathbb{Z}$, sei $\fab$ stetig und monoton, $a < b, f \geq 0$. Es gilt
	\begin{description}[noitemsep]
		\item $f$ monoton wachsend $\rightarrow \sum_{k=a}^{b-1} f(k) \leq \int_{a}^{b}f(x)dx \leq \sum_{k=a+1}^{b}f(k)$
		\item $f$ monoton fallend  $\rightarrow \sum_{k=a+1}^{b} f(k) \leq \int_{a}^{b}f(x)dx \leq \sum_{k=a}^{b-1}f(k)$
	\end{description}
\end{satz}

\begin{satz}[Integralkriterium für Reihen]
	$\rightarrow$ siehe Blatt Reihen
\end{satz}

\begin{satz}[Riemannsche Zetafunktion]
	$\rightarrow$ siehe Blatt Reihen
\end{satz}

\begin{satz}
	Die folgenden uneigentlichen Integrale gelten: \\
	$\int_{0}^{1} \frac{1}{x^\alpha} dx = 
		\begin{cases}
			+ \infty              &, \alpha > 1 \\ 
	 		\frac{1}{1 - \alpha}  &, \alpha < 1
		\end{cases}$, 
	$\int_{1}^{\infty} \frac{1}{x^\alpha} dx = 
		\begin{cases}
			\frac{1}{\alpha - 1}  &, \alpha > 1 \\
			+ \infty              &, \alpha < 1 
		\end{cases}$
\end{satz}

\pagebreak

\section{Differentialrechnung mehrerer Veränderlicher}

\begin{definition}[Parametrisierbare Kurve]
	Eine parametrisierbare Kurve ist eine Abbildung $\function{\gamma}{[a, b]}{\realset^n} : t \mapsto (\gamma_1(t), \dots, \gamma_n(t))$, deren Komponenten $\gamma_i$ stetig sind. $\gamma$ heißt differenzierbar, wenn all $\gamma_i$ differenzierbar sind. Die Menge $\gamma([a,b]) ) \{\gamma(t) \medspace | \medspace t \in [a,b] \}$ heißt Spur von $\gamma$.
\end{definition}

\begin{definition}[Tangentialvektor]
	Eine Kurve $\function{\gamma}{[a,b]}{\realset^n}$ sei differenzierbar. $\gamma'(t) := (\suboneton{\gamma'})$ heißt \emph{Tangentialvektor} an der Stelle $t$. Falls $\gamma'(t) \neq 0$, so heißt $T_\gamma = \frac{\gamma'(t)}{||\gamma'(t)||}$ \emph{Tangentialeinheitsvektor}.
\end{definition}

\begin{definition}[partielle Ableitung]
	Betrachte $\function{f}{\realset^n}{\realset} : (\suboneton{x}) \mapsto f(\suboneton{x}) \in \realset$. Ist die Funktion $\function{f}{\realset}{\realset} : \xi \mapsto f(x_1, \dots, x_{k-1}, \xi, x_{k+1}, \dots, x_n)$ differenzierbar, heißt ihre Ableitung an der Stelle $x_k$ partielle Ableitung. Wir schreiben $\frac{\partial f}{\partial x_k}$ bzw. $\partial_k f(x)$. Alternative Notationen sind: $f_{x_1}(x) := \partialf{f(x)}{x_1}$ oder $f_{x_1x_2}(x) := \partialf{^2 f(x)}{x_1 \partial x_2} = \frac{\partial}{\partial x_1}(\partialf{f(x)}{x_2})$ Der Vektor $\nabla f(x) = grad(f(x)) = (\partial_1 f(x) \dots \partial_n f(x))^T$ heißt Gradient.
\end{definition}

\begin{satz}[Satz von Schwarz]
	Für zweimal stetig differenzierbare Functionen $f \in C^2$ gilt: $\partialf{^2f}{x \partial y} = \partialf{^2f}{y \partial x}$
\end{satz}

\begin{definition}
	Die Matrix $Hf(x) := (\partial_j \partial_i f(x))_{1 \leq i \leq j \leq n}$ heißt \emph{Hesse-Matrix}.
\end{definition}

\begin{satz}
	Sei $U \subseteq \realset^n$ offen, $\function{f}{U}{\realset}$ zweimal stetig differenzierbar, d.h. $\partial_i \partial_j$ existiert für alle $i, j$. Dann gilt:
	\begin{enumerate}[noitemsep]
		\item Falls $f$ in $x \in U$ ein lokales Extremum besitzt, gilt $\nabla f(x) = 0$. Im Falle eines lokalen Minimums ist $Hf(x)$ positiv semidefinit, im Falle eines lokalen Maximums $Hf(x)$ negativ semidefinit.
		\item Falls $\nabla f(x) = 0$ und $Hf(x)$ positiv definit, dann hat $f$ ein striktes lokales Minimum. Falls $\nabla f(x) = 0$ und $Hf(x)$ negativ definit, dann hat $f$ ein striktes lokales Maximum. 
	\end{enumerate}
\end{satz}

\begin{definition}
	Sei $U \subseteq \realset^n, \function{f}{U}{\realset^m}$. $f$ heißt in $x \in U $ differenzierbar, falls es eine lineare Abbildung $\function{A}{\realset^n}{\realset^m} : h \mapsto A(h) := Ah$ gibt, sodass gilt: $f(x+h) = f(x) + Ah + \mathcal{o}(||h||)$ für $h \rightarrow 0$. Diese Abbildung kann man als Matrix beschreiben $A \in \realset^{n \times m}$. Es gilt: $f$ ist differenzierbar $\leftrightarrow$ alle Komponenten sind in $x$ differenzierbar.
	Die Matrix $A$ heißt auch Jacobi Matrix. Man schreibt:
	$A = Jf(x) = (\frac{\partial f_i}{\partial x_j})_{1 \leq i \leq n, 1 \leq j \leq m} \in \realset^{m \times n }$
\end{definition}

\begin{definition}[Multivariate Ableitungen]
	Zusammenfassend gilt:
	\begin{itemize}[noitemsep]
		\item Skalar nach Vektor: $\f{\realset^n}{\realset} : \vec{x} \in \realset^n \mapsto f(\vec{x}) \in \realset \Rightarrow \nabla f(\vec{x}) = \nabla f = (\frac{\partial f}{\partial \vec{x}})^T = (\frac{\partial f(\vec{x})}{\partial x_1}, ..., \frac{\partial f(\vec{x})}{\partial x_n})^T$
		\item Vektor nach Skalar: $\vec{f} : \realset \rightarrow \realset^n : x \in \realset \mapsto \vec{f}(x) \in \realset^n \Rightarrow \frac{\partial \vec{f}(x)}{\partial x} = (\frac{\partial f_1(x)}{\partial x}, ..., \frac{\partial f_n(x)}{\partial x})^T$  
		\item Vektor nach Vektor:  $\vec{f} : \realset^n \rightarrow \realset^m : x^n \in \realset^n \mapsto \vec{f}(\vec{x}) \in \realset^n \Rightarrow J\vec{f} (\vec{x}) = (\frac{\partial f_{i}(\vec{x})}{\partial x_j})$
		\item Skalar nach Matrix: $f : \mathbb{R}^{n \times m} \rightarrow \realset : A \in \realset^{m \times n} \mapsto f(A) \in \realset \Rightarrow \nabla f(A) = (\frac{\partial f(A)}{\partial A_{i, j}})$   
	\end{itemize}
\end{definition}

\begin{definition}[Totale Ableitung/Materialableitung]
	Das Totale Differential beschreibt die Änderung in einer kleinen Umgebung eines Punktes $p$. Sei $\f{\realset^n}{\realset}$ total differenzierbar:
	
	\begin{align*}
		\frac{d f (\vec{x}) }{d \vec{x}} = d f(\vec{x}) = \sum_{i = 1}^{n} \frac{\partial f (\vec{x}) }{\partial x_i}
	\end{align*}
	
	In der Physik wird dies auch als \textbf{Materialableitung} bezeichnet. Ist $f$ von anderen Funktionen abhängig, z.B. $f(t, u(t))$, so ist die Kettenregel zu verwenden:
	
	\begin{align*}
		d f(t, u(t))  = \frac{\partial f (t, u(t))}{\partial t} + \frac{\partial f (t, u(t))}{\partial u(t)} \cdot \frac{\partial u (t)}{\partial t}
	\end{align*}
	
		
\end{definition}

\begin{definition}[Divergenz]
	Die Divergenz eines Vektorfeld beschreibt den Zu - order Abfluss einer Größe. Sei $\vec{f} : \realset^n \rightarrow \realset^n$:

	\begin{align*}
	 div(f) = \nabla \cdot \vec{f}(\vec{x}) = \sum_{i = 1}^{n} \frac{\partial f_i (\vec{x}) }{\partial x_i}
	\end{align*}
	
\end{definition}


\begin{definition}[Richtungsableitung]
	Ähnlich wie die partielle Ableitung beschreibt die Richtungsableitung die lokale Änderungsrate, allerdings in einer vorgegebenen Richtung eines normierten Vektors $\vec{v}$ und nicht entlang der Einheitsvektoren:
	
	\begin{align*}
	  D_v f(x_0) = \frac{\partial f(x_0)}{\partial \vec{v}} = \lim_{h \rightarrow 0} \frac{f(x_0  + h \cdot \vec{v}) - f(x_0)}{h}
	\end{align*}

\end{definition}

\begin{definition}[Rotation]
	Die Rotation erzeugt das Wirbelfeld zu einem Vektorfeld:
	
	\begin{align*}
		curl(v(t, \vec{x})) = \nabla \times v(t,\vec{x}) = \begin{pmatrix} \frac{\partial}{\partial y} v_z(t, \vec{x}) - \frac{\partial}{\partial z} v_y(t, \vec{x}) \\
		\frac{\partial}{\partial z} v_x(t, \vec{x}) - \frac{\partial}{\partial x} v_z(t, \vec{x}) \\ \frac{\partial}{\partial x} v_y(t, \vec{x}) - \frac{\partial}{\partial y} v_x(t, \vec{x})
		\end{pmatrix} 
	\end{align*}
\end{definition}

\begin{satz}[Berechnung der Richtungsableitung]
	Für $f$ stetig differenzierbar lässt sich die Richtungsableitung mithilfe des Skalarprodukts wie folgt berechnen:
	
	\begin{align*}
		D_v f(x_0) = \langle \nabla f(x_0), v \rangle
	\end{align*}
\end{satz}

\section{Integralrechnung mehrere Veränderlicher}

\pagebreak

\section{Gewöhnliche Differentialgleichungen}
\begin{definition}[Differentialgleichungen mit separierbar rechter Hälfte]
	
	Gestalt: $\frac{d y}{d x} = y'(x) = f(x)g(y(x)), \function{f,g}{\realset}{\realset}$ stetig. Ansatz falls $g(y(x)) \neq 0$:
	
	\begin{equation*}
		\int_{t_0}^{t} \frac{y'(x)}{g(y(x))} dx = \int_{t_0}^{t} f(x) dx \rightarrow \int_{y(t_0)}^{y(t)} \frac{1}{g(s)} ds = \int_{t_0}^{t} f(x) dx
	\end{equation*}
\end{definition}

\begin{definition}[Lineare DGL erster Ordnung]
	Die folgenden Lösungsverfahren gelten:
	\begin{itemize}
		\item Homogen $y'(x) + a(x)y(x) = 0$ Ansatz: bringe $a(x)y(x)$ auf die rechte Seite und löse diese DGL mit separierbarer rechter Hälfte
		\item Inhomogen: $y'(x) + a(x)y(x) = f(x)$ 
			\begin{enumerate} [noitemsep]
				\item Löse $y'(x) +a(x)y(x) = 0 \rightarrow $ allgemeine Lösung der homogenen LDGL
				\item Finde eine Lösung der inhomogenen LDGL. Ansatz: \emph{Variation der Konstanten}. Setze $y(x) = c(x) \cdot$ Ergebnis der homogenen LDGL
				\item Summiere Ergebnisse aus 1) und 2)
			\end{enumerate}
	\end{itemize}
\end{definition}

\begin{definition}[Lineare DGL zweiter Ordnung mit konstanten Koeffizienten]
	Die folgenden Lösungsverfahren gelten:
	
	\begin{itemize}
		\item Homogen $y''(x) + a y'(x) + b y(x) = 0$. Ansatz: $e^{\lambda x} = y(x)$. Leite ab und löse die entstehende quadratische Gleichung.
		\item Inhomogen $y''(x) + a y'(x) + b y(x) = f(x) $
		\begin{enumerate} [noitemsep]
			\item Löse $y''(x) + a y'(x) + b y(x) = 0$
			\item Finde eine Lösung der inhomogenen LDGL 
			\begin{itemize}
				\item falls $f(x) = e^{\alpha t} (a_1 cos(\omega t) + a_2 sin(\omega t)) \rightarrow $ Ansatz: $y(x) = e^{\alpha x} (b_1 cos(\omega x + b_2 sin(\omega x)))$
				\item falls $f(x)$ Polynom $\rightarrow$ Ansatz $y(x)$ ist generisches Polynom vom gleichen Grad. Löse das entsehende GLeichungssystem
			\end{itemize}
			\item Summiere Ergebnisse aus 1) und 2)
		\end{enumerate}
	\end{itemize}
\end{definition}

\begin{definition}[Anfangswertproblem]
	Setze $y(0)$ und löse nach den verbleibenden Konstanten. Erstelle neue Lösung mit konkreten Werten der konstanten.
\end{definition}

\section{Partielle Differentialgleichungen}

\pagebreak


